Here’s a concise and professional description tailored for your GitHub repository:

🎵 Gesture-Controlled iOS Music Player

An innovative iOS music player application that uses CoreML and Vision frameworks to enable real-time hand gesture recognition for controlling playback. This app allows users to play, pause, skip, and rewind songs using predefined gestures detected through the iPhone’s front camera, offering a touch-free and intuitive user experience.

🚀 Features
	•	Real-Time Gesture Detection: Seamless, low-latency recognition of hand gestures using a custom-trained CNN model.
	•	Touch-Free Music Control: Perform essential playback actions without touching your device.
	•	CoreML Integration: On-device machine learning for fast, secure processing without needing an internet connection.
	•	SwiftUI Interface: Modern, minimalistic UI inspired by Apple Music for a familiar and smooth experience.
	•	Lock Screen Live Activity: Control playback and view song information even when the device is locked.

🛠️ Tech Stack
	•	Swift 6 & SwiftUI
	•	CoreML & Vision Framework
	•	Custom CNN Model trained with a self-created hand gesture dataset
	•	iOS 18.2 | Xcode 16.2

📂 Dataset & Model

The model was trained on a custom dataset generated by recording and extracting frames of various hand gestures. These images were preprocessed, labeled, and used to train a CNN via CreateML, achieving optimized performance for real-time detection.

🔮 Future Enhancements
	•	Customizable gestures
	•	Shuffle and sort features for the song library
	•	Enhanced UI elements like a progress bar and dynamic playlists

Let me know if you want to add installation instructions or contribution guidelines!
